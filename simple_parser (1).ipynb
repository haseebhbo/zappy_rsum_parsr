{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_parser.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnWkbHT03Rih",
        "outputId": "30cf5ece-3980-49db-add5-9a0fa3e97623"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypdf2\n",
            "  Downloading PyPDF2-2.10.3-py3-none-any.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pypdf2) (4.1.1)\n",
            "Installing collected packages: pypdf2\n",
            "Successfully installed pypdf2-2.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "pdf_Obj = open('/content/Resume22.PDF', 'rb')"
      ],
      "metadata": {
        "id": "UvWDQpLstq80"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a pdf reader object\n",
        "pdfReader = PyPDF2.PdfFileReader(pdf_Obj)\n",
        "print(pdfReader.numPages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJNvQI8h3846",
        "outputId": "b16bf291-a2e4-4950-8176-8ad022a5e1ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page = pdfReader.getPage(0)\n",
        "print(page.extractText())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-EHdI3G4GW_",
        "outputId": "b622d9a0-ec97-432e-9a19-0b3274dede2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAZEEB O\n",
            "7034432111 \n",
            "Haseebhbo7@gmail.com \n",
            "Ottakath (H) Malappuram kerala \n",
            "OBJECTIVES\n",
            "To obtain employment with a company that o\u0000ers a positive atmosphere to learn and implement new skills and technologies for the\n",
            "betterment of the organization.\n",
            "EXPERIENCE\n",
            "QUALIFICATIONS\n",
            "Technical Skills\n",
            "Machine learning\n",
            "Bigdata: Hadoop\n",
            "Database : MySQL\n",
            "TableauManagement Skills\n",
            "Work ethic\n",
            "Microsoft Excel\n",
            "Statistical analysis and computing\n",
            "Processing large data setsSKILLS\n",
            "PROJECTS\n",
            "ACHIEVEMENTS11/2021 - PresentCochin\n",
            "At Luminar Technolab\n",
            "Analyze large amounts of information to discover trends and patterns, Build predictive models and machine-learning\n",
            "algorithms.\n",
            "7/2016 - 9/2020B Tech computer science engineering\n",
            "From APJ Abdul kalam University\n",
            "6/2014 - 3/2016Plus Two\n",
            "From HSE\n",
            "6/2011 - 8/2012SSLC\n",
            "From Kerala state board\n",
            "75%\n",
            "80%\n",
            "95%\n",
            "80%\n",
            "10/2021 - PresentFake News Detection using machine learning\n",
            "Natural language processing NLP is used to detect fake news with Python. We took a Fake and True News dataset,\n",
            "implemented a Text cleaning function, T\u0000dfVectorizer, initialized Multinomial Naive Bayes Classi\u0000er, and \u0000t our\n",
            "model. We ended up obtaining an accuracy of 95.31% in magnitude. Preprocessing steps : Cleaning data Convert to\n",
            "lowercase Stop word removal Lemmatization T\u0000dfVectorization FITTING THE MODEL (Machine learning algorithm)\n",
            "8/2021NACTET certi\u0000cation in Data science\n",
            "From Luminar Technolab\n",
            "5/2022Online certi\u0000cation\n",
            "From GREAT LEARNING\n",
            "https://olympus1.mygreatlearning.com/course_certi\u0000cate/ZUZTVBXJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assingn to txt variable\n",
        "text=page.extractText()"
      ],
      "metadata": {
        "id": "51ijvMBt4VSp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        "\n",
        "re.findall(EMAIL_REG, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n28wsVv65Cwm",
        "outputId": "c736b1b5-3e4e-4d80-acdf-e0689040c388"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aseebhbo7@gmail.com']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ph = re.compile(r\"\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\")\n",
        "\n",
        "a=re.findall(ph,text)\n",
        "if len(a)==0:\n",
        "  ph = re.compile(r\"\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d\")\n",
        "  a=re.findall(ph,text)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux_0kgg07XF-",
        "outputId": "41a59668-2237-4a93-eb8e-6de72ddae4d9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['7034432111']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5ZEkx108rnV",
        "outputId": "239ed0bc-7703-4b4b-e0ce-a30b64ba0f7d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        " nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kl2BrXI99mt",
        "outputId": "5d190283-fa33-4eb2-cd1b-62f4d4253ac9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "tk=word_tokenize(text)"
      ],
      "metadata": {
        "id": "CSOj02XQ7czC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GMeAtIai-Dyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G09PMC8n-Qvo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}